X = c(20.9, 13.6, 15.7, 6.3, 2.7, 25.6, 4, 20.9, 7.8, 27.1, 25.2, 19, 17.8, 22.8, 12.5, 21.1, 22, 22.4, 5.1, 16, 20.7, 15.7, 5.5, 18.9, 22.9, 15.5, 18.6, 19.3, 14.2, 12.3, 11.8, 26.8, 17, 5.7, 12, 19.8, 19, 23.6, 19.9, 8.4, 22, 18.1, 21.6, 17, 12.4, 2.9, 22.6, 20.8, 18.2, 14.2, 17.3, 14.5, 8.6, 9.1, 2.6, 19.8, 20, 22.2, 10.2, 12.9, 20.9, 21.1, 7.3, 5.8, 23.1, 17, 21.5, 10.1, 18.4, 22.6, 21.2, 21.5, 22.4, 17.3, 16, 25, 22.4, 23.9, 23, 21.9, 19, 28.6, 16, 22.5, 23.2, 8.7, 23.4, 15.3, 25.6, 19.2, 17.4, 23.8, 20.4, 19, 3.6, 23.4, 19.6, 17.5, 16.5, 22, 19.7, 7.35, 18, 17.8, 9.6, 15, 12, 17.7, 21.4, 17, 22.1, 18.9, 15.05, 12.9, 19.3, 15.3, 13.6, 15.4, 10.6, 11.3, 11.8, 22.2, 22.2, 13.1, 7.4, 4.5, 11.7, 19.5, 19.9, 11.6, 13.9, 15.5, 11, 18.6, 17.6, 12.7, 20.9, 18.8, 22.4, 21.2, 18.2, 15.3, 13.6, 7.3, 17.4, 17.4, 10.5, 22.9, 23.2, 13.8, 14.8, 22.2, 20.9, 13, 18.9, 19, 15.2, 16.8, 18, 24.6, 15.4, 17.2, 23.2, 22.8, 25.5, 7.8, 6, 6.4, 19, 13.5, 23.7, 18, 22.2, 22.4, 9.3, 13.7, 18.9, 20.5, 23.3, 20.8, 18.4, 4.5, 12.2, 16.9, 13.5, 17.8, 16.9, 20.4, 19.5, 22.2, 24.5, 21.2, 16.5, 18, 16.4, 3.9, 17.9, 22, 12.9, 21, 18, 9.2, 15.9, 8.1, 8.3, 10.7, 12, 19.9, 13.6, 17.3, 11.5, 12.4, 15.1, 22, 19.3, 17.5, 14.5, 14.7, 17.5, 19.6, 12.9, 20.3, 17.9, 20.2, 18.3, 9.5, 19, 21, 13.1, 20.4, 16.3, 18.3, 11.8, 23.3, 15.2, 20, 17.9, 12, 19.6, 18.5, 16.2, 10.9, 17.8, 13.8, 10, 17.9, 15.6, 20.3, 14.9, 18.6, 12.5, 18.2, 16, 18.7, 18, 15.3, 19, 17.9, 15.8, 17.7, 14.4, 19.6, 18.3, 18.7, 17.8, 18, 10.1, 18.8, 16.4, 21.2, 16.6, 16.7, 17.8, 16.5, 19.3, 16.3, 14.2, 13, 9.4, 19.7, 13.4, 2.6, 17.6, 16.7, 17.6, 5.8, 17.6, 20.1, 18.2, 16.7, 14, 13.9, 5.1, 16.6, 3.9, 17.5, 18)
)
NormalMeanN <- "
model {
mu ~ dnorm(mu0,T) # prior on the mean
S ~ dnorm(S0, p)
for(i in 1:N){
X[i] ~ dnorm(mu,S) # data model
}
}
"
j.model   <- jags.model (file = textConnection(NormalMeanN),
data = data)
data = list(
N = 297,
mu0=20,
T=0.01,
S0 = 0,
p = 1,
X = c(20.9, 13.6, 15.7, 6.3, 2.7, 25.6, 4, 20.9, 7.8, 27.1, 25.2, 19, 17.8, 22.8, 12.5, 21.1, 22, 22.4, 5.1, 16, 20.7, 15.7, 5.5, 18.9, 22.9, 15.5, 18.6, 19.3, 14.2, 12.3, 11.8, 26.8, 17, 5.7, 12, 19.8, 19, 23.6, 19.9, 8.4, 22, 18.1, 21.6, 17, 12.4, 2.9, 22.6, 20.8, 18.2, 14.2, 17.3, 14.5, 8.6, 9.1, 2.6, 19.8, 20, 22.2, 10.2, 12.9, 20.9, 21.1, 7.3, 5.8, 23.1, 17, 21.5, 10.1, 18.4, 22.6, 21.2, 21.5, 22.4, 17.3, 16, 25, 22.4, 23.9, 23, 21.9, 19, 28.6, 16, 22.5, 23.2, 8.7, 23.4, 15.3, 25.6, 19.2, 17.4, 23.8, 20.4, 19, 3.6, 23.4, 19.6, 17.5, 16.5, 22, 19.7, 7.35, 18, 17.8, 9.6, 15, 12, 17.7, 21.4, 17, 22.1, 18.9, 15.05, 12.9, 19.3, 15.3, 13.6, 15.4, 10.6, 11.3, 11.8, 22.2, 22.2, 13.1, 7.4, 4.5, 11.7, 19.5, 19.9, 11.6, 13.9, 15.5, 11, 18.6, 17.6, 12.7, 20.9, 18.8, 22.4, 21.2, 18.2, 15.3, 13.6, 7.3, 17.4, 17.4, 10.5, 22.9, 23.2, 13.8, 14.8, 22.2, 20.9, 13, 18.9, 19, 15.2, 16.8, 18, 24.6, 15.4, 17.2, 23.2, 22.8, 25.5, 7.8, 6, 6.4, 19, 13.5, 23.7, 18, 22.2, 22.4, 9.3, 13.7, 18.9, 20.5, 23.3, 20.8, 18.4, 4.5, 12.2, 16.9, 13.5, 17.8, 16.9, 20.4, 19.5, 22.2, 24.5, 21.2, 16.5, 18, 16.4, 3.9, 17.9, 22, 12.9, 21, 18, 9.2, 15.9, 8.1, 8.3, 10.7, 12, 19.9, 13.6, 17.3, 11.5, 12.4, 15.1, 22, 19.3, 17.5, 14.5, 14.7, 17.5, 19.6, 12.9, 20.3, 17.9, 20.2, 18.3, 9.5, 19, 21, 13.1, 20.4, 16.3, 18.3, 11.8, 23.3, 15.2, 20, 17.9, 12, 19.6, 18.5, 16.2, 10.9, 17.8, 13.8, 10, 17.9, 15.6, 20.3, 14.9, 18.6, 12.5, 18.2, 16, 18.7, 18, 15.3, 19, 17.9, 15.8, 17.7, 14.4, 19.6, 18.3, 18.7, 17.8, 18, 10.1, 18.8, 16.4, 21.2, 16.6, 16.7, 17.8, 16.5, 19.3, 16.3, 14.2, 13, 9.4, 19.7, 13.4, 2.6, 17.6, 16.7, 17.6, 5.8, 17.6, 20.1, 18.2, 16.7, 14, 13.9, 5.1, 16.6, 3.9, 17.5, 18)
)
NormalMeanN <- "
model {
mu ~ dnorm(mu0,T) # prior on the mean
S ~ dnorm(S0, p)
for(i in 1:N){
X[i] ~ dnorm(mu,S) # data model
}
}
"
j.model   <- jags.model (file = textConnection(NormalMeanN),
data = data)
data = list(
N = 297,
mu0=20,
T=0.01,
S0 = 1,
p = .1,
X = c(20.9, 13.6, 15.7, 6.3, 2.7, 25.6, 4, 20.9, 7.8, 27.1, 25.2, 19, 17.8, 22.8, 12.5, 21.1, 22, 22.4, 5.1, 16, 20.7, 15.7, 5.5, 18.9, 22.9, 15.5, 18.6, 19.3, 14.2, 12.3, 11.8, 26.8, 17, 5.7, 12, 19.8, 19, 23.6, 19.9, 8.4, 22, 18.1, 21.6, 17, 12.4, 2.9, 22.6, 20.8, 18.2, 14.2, 17.3, 14.5, 8.6, 9.1, 2.6, 19.8, 20, 22.2, 10.2, 12.9, 20.9, 21.1, 7.3, 5.8, 23.1, 17, 21.5, 10.1, 18.4, 22.6, 21.2, 21.5, 22.4, 17.3, 16, 25, 22.4, 23.9, 23, 21.9, 19, 28.6, 16, 22.5, 23.2, 8.7, 23.4, 15.3, 25.6, 19.2, 17.4, 23.8, 20.4, 19, 3.6, 23.4, 19.6, 17.5, 16.5, 22, 19.7, 7.35, 18, 17.8, 9.6, 15, 12, 17.7, 21.4, 17, 22.1, 18.9, 15.05, 12.9, 19.3, 15.3, 13.6, 15.4, 10.6, 11.3, 11.8, 22.2, 22.2, 13.1, 7.4, 4.5, 11.7, 19.5, 19.9, 11.6, 13.9, 15.5, 11, 18.6, 17.6, 12.7, 20.9, 18.8, 22.4, 21.2, 18.2, 15.3, 13.6, 7.3, 17.4, 17.4, 10.5, 22.9, 23.2, 13.8, 14.8, 22.2, 20.9, 13, 18.9, 19, 15.2, 16.8, 18, 24.6, 15.4, 17.2, 23.2, 22.8, 25.5, 7.8, 6, 6.4, 19, 13.5, 23.7, 18, 22.2, 22.4, 9.3, 13.7, 18.9, 20.5, 23.3, 20.8, 18.4, 4.5, 12.2, 16.9, 13.5, 17.8, 16.9, 20.4, 19.5, 22.2, 24.5, 21.2, 16.5, 18, 16.4, 3.9, 17.9, 22, 12.9, 21, 18, 9.2, 15.9, 8.1, 8.3, 10.7, 12, 19.9, 13.6, 17.3, 11.5, 12.4, 15.1, 22, 19.3, 17.5, 14.5, 14.7, 17.5, 19.6, 12.9, 20.3, 17.9, 20.2, 18.3, 9.5, 19, 21, 13.1, 20.4, 16.3, 18.3, 11.8, 23.3, 15.2, 20, 17.9, 12, 19.6, 18.5, 16.2, 10.9, 17.8, 13.8, 10, 17.9, 15.6, 20.3, 14.9, 18.6, 12.5, 18.2, 16, 18.7, 18, 15.3, 19, 17.9, 15.8, 17.7, 14.4, 19.6, 18.3, 18.7, 17.8, 18, 10.1, 18.8, 16.4, 21.2, 16.6, 16.7, 17.8, 16.5, 19.3, 16.3, 14.2, 13, 9.4, 19.7, 13.4, 2.6, 17.6, 16.7, 17.6, 5.8, 17.6, 20.1, 18.2, 16.7, 14, 13.9, 5.1, 16.6, 3.9, 17.5, 18)
)
NormalMeanN <- "
model {
mu ~ dnorm(mu0,T) # prior on the mean
S ~ dnorm(S0, p)
for(i in 1:N){
X[i] ~ dnorm(mu,S) # data model
}
}
"
j.model   <- jags.model (file = textConnection(NormalMeanN),
data = data)
inits <- list()
inits[[1]] <- list(mu = 15, S = .5)
inits[[2]] <- list(mu = 20, S = 1)
inits[[3]] <- list(mu = 25, S = 1.5)
j.model   <- jags.model (file = textConnection(NormalMeanN),
data = data,
inits = inits,
n.chains = 3)
jags.out   <- coda.samples (model = j.model,
variable.names = c("mu", "S"),
n.iter = 1000)
plot(jags.out)
gelman.diag(jags.out)
GBR <- gelman.plot(jags.out)
burnin = 400                                ## determine convergence
jags.burn <- window(jags.out,start=burnin)  ## remove burn-in
plot(jags.burn)                             ## check diagnostics post burn-in
acfplot(jags.burn)
effectiveSize(jags.burn)
jags.out2 <- coda.samples(j.model,
variable.names = c("mu", "S"),
10000)
summary(jags.out2)
NormalMeanN <- "
model {
mu ~ dnorm(mu0,T) # prior on the mean
for(i in 1:N){
X[i] ~ dnorm(mu,S) # data model
}
}
"
data = list(
N = 297,
mu0=20,
T=0.01,
S = 1/27,
X = c(20.9, 13.6, 15.7, 6.3, 2.7, 25.6, 4, 20.9, 7.8, 27.1, 25.2, 19, 17.8, 22.8, 12.5, 21.1, 22, 22.4, 5.1, 16, 20.7, 15.7, 5.5, 18.9, 22.9, 15.5, 18.6, 19.3, 14.2, 12.3, 11.8, 26.8, 17, 5.7, 12, 19.8, 19, 23.6, 19.9, 8.4, 22, 18.1, 21.6, 17, 12.4, 2.9, 22.6, 20.8, 18.2, 14.2, 17.3, 14.5, 8.6, 9.1, 2.6, 19.8, 20, 22.2, 10.2, 12.9, 20.9, 21.1, 7.3, 5.8, 23.1, 17, 21.5, 10.1, 18.4, 22.6, 21.2, 21.5, 22.4, 17.3, 16, 25, 22.4, 23.9, 23, 21.9, 19, 28.6, 16, 22.5, 23.2, 8.7, 23.4, 15.3, 25.6, 19.2, 17.4, 23.8, 20.4, 19, 3.6, 23.4, 19.6, 17.5, 16.5, 22, 19.7, 7.35, 18, 17.8, 9.6, 15, 12, 17.7, 21.4, 17, 22.1, 18.9, 15.05, 12.9, 19.3, 15.3, 13.6, 15.4, 10.6, 11.3, 11.8, 22.2, 22.2, 13.1, 7.4, 4.5, 11.7, 19.5, 19.9, 11.6, 13.9, 15.5, 11, 18.6, 17.6, 12.7, 20.9, 18.8, 22.4, 21.2, 18.2, 15.3, 13.6, 7.3, 17.4, 17.4, 10.5, 22.9, 23.2, 13.8, 14.8, 22.2, 20.9, 13, 18.9, 19, 15.2, 16.8, 18, 24.6, 15.4, 17.2, 23.2, 22.8, 25.5, 7.8, 6, 6.4, 19, 13.5, 23.7, 18, 22.2, 22.4, 9.3, 13.7, 18.9, 20.5, 23.3, 20.8, 18.4, 4.5, 12.2, 16.9, 13.5, 17.8, 16.9, 20.4, 19.5, 22.2, 24.5, 21.2, 16.5, 18, 16.4, 3.9, 17.9, 22, 12.9, 21, 18, 9.2, 15.9, 8.1, 8.3, 10.7, 12, 19.9, 13.6, 17.3, 11.5, 12.4, 15.1, 22, 19.3, 17.5, 14.5, 14.7, 17.5, 19.6, 12.9, 20.3, 17.9, 20.2, 18.3, 9.5, 19, 21, 13.1, 20.4, 16.3, 18.3, 11.8, 23.3, 15.2, 20, 17.9, 12, 19.6, 18.5, 16.2, 10.9, 17.8, 13.8, 10, 17.9, 15.6, 20.3, 14.9, 18.6, 12.5, 18.2, 16, 18.7, 18, 15.3, 19, 17.9, 15.8, 17.7, 14.4, 19.6, 18.3, 18.7, 17.8, 18, 10.1, 18.8, 16.4, 21.2, 16.6, 16.7, 17.8, 16.5, 19.3, 16.3, 14.2, 13, 9.4, 19.7, 13.4, 2.6, 17.6, 16.7, 17.6, 5.8, 17.6, 20.1, 18.2, 16.7, 14, 13.9, 5.1, 16.6, 3.9, 17.5, 18)
)
inits <- list()
inits[[1]] <- list(mu = 15)
inits[[2]] <- list(mu = 20)
inits[[3]] <- list(mu = 25)
j.model   <- jags.model (file = textConnection(NormalMeanN),
data = data,
inits = inits,
n.chains = 3)
jags.out   <- coda.samples (model = j.model,
variable.names = c("mu"),
n.iter = 1000)
plot(jags.out)
gelman.diag(jags.out)
GBR <- gelman.plot(jags.out)
burnin = 400                                ## determine convergence
jags.burn <- window(jags.out,start=burnin)  ## remove burn-in
plot(jags.burn)                             ## check diagnostics post burn-in
acfplot(jags.burn)
effectiveSize(jags.burn)
jags.out2 <- coda.samples(j.model,
variable.names = c("mu"),
10000)
summary(jags.out2)
summary(jags.out2)
library(neonUtilities)
setwd("~/Downloads")
tryspecies <- read.csv("TryAccSpecies.txt", sep='t')
head(tryspecies)
tryspecies <- read.csv("TryAccSpecies.txt", sep='\t')
head(tryspecies)
bos_species <- read.csv("Ecological Considerations - Boston-approved trees.csv")
try_species <- read.csv("TryAccSpecies.txt", sep='\t')
head(bos_species)
intersect(bos_species$Scientific.name,try_species$AccSpeciesName)
common_spec <- intersect(bos_species$Scientific.name,try_species$AccSpeciesName)
try_species[try %in% common_spec,]
common_spec
try_species[try_species$AccSpeciesName %in% common_spec,]$AccSpeciesID
# get species in both datasets (less straightforward)
setdiff(bos_species$Scientific.name, common_spec)
library(stringr)
# get species in both datasets (less straightforward)
tryagain <- setdiff(bos_species$Scientific.name, common_spec)
word(tryagain, 1)
i <- 1
grep(genus[[i]], try_species$AccSpeciesName)
genus <- word(tryagain, 1)
grep(genus[[i]], try_species$AccSpeciesName)
genus[[i]]
try_species$AccSpeciesName
grep(genus[[i]], as.character(try_species$AccSpeciesName))
try_species[grep(genus[[i]], as.character(try_species$AccSpeciesName)),]
tryagain
try_species[grep("Acer gin", as.character(try_species$AccSpeciesName)),]
try_species[grep("Malus", as.character(try_species$AccSpeciesName)),]
iconv("try_species$AccSpeciesName", from = '', to = 'latin1')
iconv(try_species$AccSpeciesName, from = '', to = 'latin1')
try_species$AccSpeciesName <- iconv(try_species$AccSpeciesName, from = '', to = 'latin1')
try_species[grep("Malus", as.character(try_species$AccSpeciesName)),]
try_species[grep("Malus", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
try_species[grep("Prunus", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
try_species[grep("Gleditsia", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
try_species[grep("Ginkgo", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
try_species[grep("Gymnocladus", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
try_species[grep("Ulmus", as.character(try_species$AccSpeciesName)),]$AccSpeciesName
common_spec <- c(common_spec, "Prunus x yedoensis", "Gleditsia triacanthos fo. inermis", "Ginkgo biloba", "Gymnocladus dioica", "Ulmus americana")
common_spec
try_species[try_species$AccSpeciesName %in% common_spec,]$AccSpeciesID
cat(paste0(IDs, sep=","))
IDs <- try_species[try_species$AccSpeciesName %in% common_spec,]$AccSpeciesID
cat(paste0(IDs, sep=","))
#Grab all sites that have 16S sequence data.
#Get core-level sequence meta data from NEON API
req <- httr::GET("http://data.neonscience.org/api/v0/products/DP1.10108.001")
req.text <- httr::content(req, as="text")
avail <- jsonlite::fromJSON(req.text, simplifyDataFrame=T, flatten=T)
site_date <- cbind(avail$data$siteCodes[1],avail$data$siteCodes[2])
site_date
# read in actual TRY data
try <- read.csv("5797_26022019094643/5797.txt", sep="\t")
head(try)
try$TraitID
unique(try$UnitName)
try <- try[!is.na(try$TraitID),]
dim(try)
head(try)
try <- try[,-c("Reference")]
try <- try[,-c(colnames(try) %in%"Reference")]
dim(try)
head(try)
try <- try[,-c(colnames(try) %in% c("Reference"))]
head(try)
(colnames(try) %in% c("Reference")
)
try <- try[,-c(24)]
head(try)
summary(try)
# just photosynthesis
try <- try[which(try$TraitName=="Leaf photosynthesis rate per leaf area")]
# just photosynthesis
try <- try[which(try$TraitName=="Leaf photosynthesis rate per leaf area"),]
dim(try)
head(try)
aggregate(try$OrigValueStr, list(try$AccSpeciesName), mean)
aggregate(try[,OrigValueStr], list(try$AccSpeciesName), mean)
aggregate(try[,try$OrigValueStr], list(try$AccSpeciesName), mean)
colnames(try)
aggregate(try[,13], list(try$AccSpeciesName), mean)
aggregate(try[,c(13,14)], list(try$AccSpeciesName), mean)
warnings()
class(try$OrigValueStr)
as.numeric(try$OrigValueStr)
aggregate(as.numeric(try[,c(13)]), list(try$AccSpeciesName), mean)
summary(try)
head(try$OrigValueStr)
head(as.numeric(try$OrigValueStr))
head(as.numeric(as.character(try$OrigValueStr)))
aggregate(as.numeric(as.character(try$OrigValueStr)), list(try$AccSpeciesName), mean)
unique(try$UnitName)
# read in actual TRY data
try_raw <- read.csv("5797_26022019094643/5797.txt", sep="\t")
unique(try_raw$TraitName)
# read in actual TRY data
try_raw <- read.csv("5797_26022019094643/5797.txt", sep="\t")
unique(try_raw$TraitName)
# other photosynthesis
try1 <- try_raw[which(try_raw$TraitName=="Leaf photosynthesis rate per leaf dry mass"),]
dim(try1)
aggregate(as.numeric(as.character(try$OrigValueStr)), list(try$AccSpeciesName), mean)
aggregate(as.numeric(as.character(try1$OrigValueStr)), list(try1$AccSpeciesName), mean)
# read in actual TRY data
try_raw <- read.csv("5797_26022019094643/5797.txt", sep="\t")
try <- try_raw[,-c(24)]
# other photosynthesis
try2 <- try_raw[which(try$TraitName=="Leaf photosynthesis rate per leaf dry mass"),]
aggregate(as.numeric(as.character(try2$OrigValueStr)), list(try2$AccSpeciesName), mean)
head(try2)
# read in actual TRY data
try_raw <- read.csv("5797_26022019094643/5797.txt", sep="\t")
head(try)
try <- try_raw[,-c(24)]
# other photosynthesis
try2 <- try[which(try$TraitName=="Leaf photosynthesis rate per leaf dry mass"),]
head(try2)
colnames(try)
# read in actual TRY data
try_raw <- read.csv("5797_26022019094643/5797.txt", sep="\t")
colnames(try_raw)
try <- try_raw[,-c(26)]
try <- try[!is.na(try$TraitID),]
head(try)
# just photosynthesis
try1 <- try[which(try$TraitName=="Leaf photosynthesis rate per leaf area"),]
aggregate(as.numeric(as.character(try$OrigValueStr)), list(try$AccSpeciesName), mean)
summary(try)
aggregate(as.numeric(as.character(try$OrigValueStr)), list(try$AccSpeciesName), mean)
# other photosynthesis
try2 <- try[which(try$TraitName=="Leaf photosynthesis rate per leaf dry mass"),]
aggregate(as.numeric(as.character(try2$OrigValueStr)), list(try2$AccSpeciesName), mean)
try[which(try$SpeciesName=="Acer rubrum"),]
aggregate(as.numeric(as.character(try2$OrigValueStr)), list(try2$AccSpeciesName), mean)
library(neonUtilities)
getPackage(dpID = "DP1.10081.001", site_code = "BART", year_month="2014-06", package="expanded", savepath = "NEON/composition")
getPackage(dpID = "DP1.10081.001", site_code = "BART", year_month="2014-06", package="expanded", savepath = "~/Desktop/NEON/composition")
stackByTable(filepath="~/Desktop/NEON/composition", folder = T)
getPackage(dpID = "DP1.10081.001", site_code = "BART", year_month="2014-06", package="expanded", savepath = "~/Desktop/NEON/composition")
dat <- read.csv("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/BART_001-O-1-6-20140619-GEN-DNA1_16S.csv")
head(dat)
colSums(dat$individualCount)
sum(dat$individualCount)
aggregate(dat$individualCount, dat$phylum, sum)
aggregate(x = dat$individualCount, by=dat$phylum, sum)
class(dat$phylum)
aggregate(x = dat$individualCount, by=as.character(dat$phylum), sum)
aggregate(x = dat$individualCount, by=list(dat$phylum), sum)
5730/10202
getPackage(dpID = "DP1.10081.001", site_code = "BART", year_month="2014-08", package="expanded", savepath = "~/Desktop/NEON/composition")
files <- list.files("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/")
files
i <- 1
f <- files[i]
ff <- read.csv(f)
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
files <- list.files("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/")
f <- files[i]
ff <- read.csv(f)
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
head(ag)
ag[ag$Group.1=="Acidobacteria",]$x
sum(ff$individualCount)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
print(acid/sum(ff$individualCount))
}
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[i] <- acid/sum(ff$individualCount)
}
all_rel <- list()
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[i] <- acid/sum(ff$individualCount)
}
all_rel <- list()
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[[i]] <- acid/sum(ff$individualCount)
}
i <- 1
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[[i]] <- acid/sum(ff$individualCount)
all_rel
all_rel <- list()
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Acidobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[[i]] <- acid/sum(ff$individualCount)
}
all_rel
mean(all_rel, na.rm = T)
class(all_rel)
class(all_rel[[1]])
unlist(all_rel)
mean(unlist(all_rel), na.rm = T)
all_rel <- list()
for (i in 1:length(files)){
f <- files[i]
ff <- read.csv(paste0("~/Desktop/NEON/composition/NEON.D01.BART.DP1.10081.001.2014-06.expanded.20180307T181957Z/", f))
ag <- aggregate(x = ff$individualCount, by=list(ff$phylum), sum)
acid <- ag[ag$Group.1=="Actinobacteria",]$x
#print(acid/sum(ff$individualCount))
all_rel[[i]] <- acid/sum(ff$individualCount)
}
mean(unlist(all_rel), na.rm = T)
all_rel
library(neonUtilities)
getPackage(dpID = "DP1.10086.00", site_code = "BART", year_month="2014-07", package="expanded", savepath = "~/Desktop/NEON/soilphys")
getPackage(dpID = "DP1.10086.001", site_code = "BART", year_month="2014-07", package="expanded", savepath = "~/Desktop/NEON/soilphys")
getPackage(dpID = "DP1.10086.001", site_code = "BART", year_month="2014-07", package="expanded", savepath = "~/Desktop/NEON/soilphys")
stackByTable(filepath="~/Desktop/NEON/soilphys", folder = T)
getPackage(dpID = "DP1.10086.001", site_code = "BART", year_month="2014-07", package="expanded", savepath = "~/Desktop/NEON/soilphys")
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
names(site_dates)
i <- 1
s <- names(site_dates)[i]
length(site_dates)
s
s <- 1
k <- 1
site <- names(site_dates)[k]
site
i
d <- site_dates[k][i]
d
d <- site_dates[k][[i]]
d
d <- site_dates[[k]][[i]]
d
foldername <- "~/Desktop/NEON/soilphys"
paste(foldername, site)
foldername <- "~/Desktop/NEON/soilphys/"
paste0(foldername, site)
foldername <- "~/Desktop/NEON/soilphys/"
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
foldername <- "~/Desktop/NEON/soilphys/" # folder has to have a slash at the end because you paste it to the sitename to create a new folder
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(foldername, site))
stackByTable(filepath=foldername, folder = T)
}
}
foldername <- "~/Desktop/NEON/soilphys/" # folder has to have a slash at the end because you paste it to the sitename to create a new folder
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
foldername <- "~/Desktop/NEON/soilphys/" # folder has to have a slash at the end because you paste it to the sitename to create a new folder
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
inner_folder <- paste0(foldername, site, "/", date)
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder, site, "/", date))
stackByTable(filepath=inner_folder, folder = T)
}
}
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
inner_folder <- paste0(foldername, site, "/", date)
dir.create(inner_folder)
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder, site, "/", date))
stackByTable(filepath=inner_folder, folder = T)
}
}
dir.create(paste0(foldername, site))
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
dir.create(paste0(foldername, site))
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date)
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder, site, "/", date))
stackByTable(filepath=inner_folder, folder = T)
}
}
inner_folder
date
site
inner_folder
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder, site, "/", date))
inner_folder
inner_folder <- paste0(foldername, site, "/", date, "/")
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder, site, "/", date))
inner_folder
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
foldername <- "~/Desktop/NEON/soilphys/" # folder has to have a slash at the end because you paste it to the sitename to create a new folder
site_dates <- list(HARV = c("2013-07", "2013-08", "2013-09"))
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
dir.create(paste0(foldername, site))
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date, "/")
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
stackByTable(filepath=inner_folder, folder = T)
}
}
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
dir.create(paste0(foldername, site))
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date, "/")
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
stackByTable(filepath=inner_folder, folder = T)
}
}
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
for (i in 1:length(site_dates[k])){ # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
dir.create(paste0(foldername, site))
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date, "/")
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
stackByTable(filepath=inner_folder, folder = T)
}
}
length(site_dates[k])
for (k in length(site_dates)){ # loops through each site "k" (right now, just "HARV")
site <- names(site_dates)[k]
dir.create(paste0(foldername, site))
for (i in 1:length(site_dates[[k]])) { # loops through each date "i" from that site
date <- site_dates[[k]][[i]]
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date, "/")
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
stackByTable(filepath=inner_folder, folder = T)
}
}
site_dates
length(site_dates)
site <- names(site_dates)[k]
site
dir.create(paste0(foldername, site))
length(site_dates[[k]])
i
i <- 1
date <- site_dates[[k]][[i]]
date
dir.create(paste0(foldername, site, "/", date))
inner_folder <- paste0(foldername, site, "/", date, "/")
inner_folder
getPackage(dpID = "DP1.10086.001", site_code = site, year_month=date, package="expanded", savepath = paste0(inner_folder))
stackByTable(filepath=inner_folder, folder = T)
install_github('NEONScience/NEON-geolocation/geoNEON', dependencies=TRUE)
library(devtools)
install_github('NEONScience/NEON-geolocation/geoNEON', dependencies=TRUE)
data <- read.csv("~/Desktop/NEON/soilphys/HARV/2013-07/stackedFiles/sls_soilCoreCollection.csv")
head(data)
data.plusSpatial <- def.extr.geo.os(data, 'namedLocation')
library(geoNEON)
data.plusSpatial <- def.extr.geo.os(data, 'namedLocation')
head(data.plusSpatial)
colnames(data.plusSpatial)[!colnames(data.plusSpatial) %in% colnames(data))
colnames(data.plusSpatial)[!colnames(data.plusSpatial) %in% colnames(data)]
Sys.Date()
end.year <- substr(Sys.Date(),1,4)
rm(list=ls())
source('paths.r')
Sys.Date()
end.year <- substr(Sys.Date(),1,4)
end.year
