
source("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/source.R")


scores_list = readRDS(here("data", paste0("summary/scoring_metrics_cv.rds")))

cal_rsq <- scores_list$calibration_metrics_long %>% filter(model_name == "all_covariates" & pretty_name != "Diversity" &
																															metric %in% c("RSQ","RSQ.1","CRPS","residual_variance", "predictive_variance", "total_PL","CRPS_truncated")) %>%
	distinct()

hindcast_rsq <- scores_list$scoring_metrics_site_lon %>% filter(model_name == "all_covariates" & pretty_name != "Diversity" &
																													 	metric %in% c("RSQ","RSQ.1","CRPS","residual_variance", "predictive_variance", "total_PL","CRPS_truncated")) %>%
	distinct() #%>% filter(pretty_group == "Bacteria")

hindcast_wide = scores_list$scoring_metrics_site  %>% filter(model_name == "all_covariates" & pretty_name != "Diversity")
hindcast_wide$CRPS_penalty = hindcast_wide$CRPS - hindcast_wide$MAE

ggplot(hindcast_wide,
			 aes(x = RSQ.1, y = CRPS_truncated,
			 		color = pretty_group)) +
	geom_point(size = 4,  alpha=.5) + geom_abline(slope=1)  +
	theme_bw(base_size=18)



ggplot(scores_list$scoring_metrics_site  %>% filter(model_name == "all_covariates" & pretty_name != "Diversity"),
			 aes(x = RSQ.1, y = RSQ,
			 		color = pretty_group)) +
	geom_point(size = 4,  alpha=.5) + geom_abline(slope=1)  +
	theme_bw(base_size=18) +
	#ggtitle("Truncated-normal CRPS worsens the scores at fine ranks") +
	facet_grid(pretty_group ~ pretty_name, drop = T, scales="free")

ggplot(cal_rsq %>% filter(metric %in% c("residual_variance", "predictive_variance", "total_PL")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = 1), alpha=.5, show.legend = F) +
	facet_grid( metric ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("calibration: Rsq predictability increases at broader ranks")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm"))

ggplot(cal_rsq %>% filter(metric %in% c("RSQ","RSQ.1","CRPS_truncated")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = 1), alpha=.5, show.legend = F) +
	facet_grid( metric ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("calibration: Rsq predictability increases at broader ranks")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm"))


ggplot(cal_rsq %>% filter(metric %in% c("RSQ.1")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = 1), alpha=.5, show.legend = F) +
	facet_grid(rows=vars(pretty_group), drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("calibration: Rsq (1:1) predictability increases at broader ranks")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm")) #+ ylim(c(-65, 2))


ggplot(cal_rsq %>% filter(metric %in% c("CRPS")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = 1), alpha=.5, show.legend = F) +
	facet_grid(metric ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("calibration CRPS: predictability decreases at broader ranks")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm"))


pass_filter <- cal_rsq %>% filter(metric == "RSQ" & value > .1) %>% select(pretty_group,model_name,pretty_name,taxon)
saveRDS(pass_filter, here("data/summary/tax_filter_pass.rds"))


scores_simple <- scores_list$scoring_metrics %>%
	select(pretty_group, model_name, pretty_name, taxon, CRPS, RSQ, `RSQ.1`) %>%
	filter(model_name == "all_covariates" & pretty_name != "Diversity") %>%
	distinct() %>%
	pivot_longer(5:7, names_to = "metric")


scores_simple_filter = scores_simple %>% merge(pass_filter, all.y=T)
#### View predictability scores by rank
ggplot(scores_simple_filter %>% filter(value > -8),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = .5), alpha=.2, show.legend = F) +
	facet_grid(metric ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("Mixed hindcast predictability trends at broader ranks (filtered by calibration Rsq)")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 14),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=14), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm"))


ggplot(scores_list$scoring_metrics_long %>% filter(model_name == "all_covariates" & pretty_name != "Diversity" &
																									 	metric %in% c("RSQ")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = .5), alpha=.2, show.legend = F) +
	facet_grid( ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("No clear taxonomic trend for R-squared")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2)

ggplot(scores_list$scoring_metrics_long %>% filter(model_name == "all_covariates" & pretty_name != "Diversity" &
																									 	metric %in% c("CRPS", "RSQ", "RSQ.1")),
			 aes(x = pretty_name, y = value,
			 		color = pretty_name)) +
	geom_violin(draw_quantiles = c(0.5), show.legend=F) +
	geom_point(size = 4, position = position_jitterdodge(jitter.width = .5), alpha=.2, show.legend = F) +
	facet_grid(metric ~ pretty_group, drop = T, scales="free") +
	# geom_jitter(aes(x = metric, y = value), width=.1,
	# 						height = 0, alpha = .8, size=4) +
	ylab("Metric scores") + xlab(NULL) +
	theme_bw(base_size=18) +
	ggtitle("Predictability decreases at broader ranks")  +
	#scale_color_manual(values = c(1,2))	+
	theme(text = element_text(size = 22),
				axis.text.x=element_text(angle = 320, vjust=1, hjust = -0.05),
				axis.title=element_text(size=24), legend.position = c(.9,1.1)) +
	#guides(color=guide_legend(title=NULL)) +
	geom_hline(yintercept = 0, linetype=2) +
	theme(plot.margin = margin(1,2,1,1, "cm"))
