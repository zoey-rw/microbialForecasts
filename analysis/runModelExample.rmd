---
title: "runModelExample"
author: "Zoey Werbin"
date: "4/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For my EE509 project, I created models to describe fluctuations in soil microbial relative abundances. Soil microbes control many of the Earth's biogeochemical processes, and we currently have limited understanding of how the soil microbiome changes over time. I focus on taxa from two major groups - bacteria and fungi - which each play important roles in decomposition, nitrogen cycling, etc. In this Rmarkdown, we will fit my model to a single group, but for my full analysis (summarized in `PrelimResults.rmd`), I fit this model to 60 different groups.

First, we load libraries and a couple of custom scripts:
```{r, echo=FALSE}
library(rjags)
library(runjags)
library(dplyr)
library(arm) #for invlogit function
library(tidyr)
library(ggplot2)
library(ecoforecastR)
source("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/functions/helperFunctions.r")
source("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/functions/prepModelData2.r")

# Read in covariate data 
cov <- readRDS("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/data/clean/EE509_model_covariates.rds")
weather <- cov[[1]]
plot.preds <- readRDS("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/data/clean/soilChemPlot.rds")[[1]]

# Read in the microbial abundance data
d <- readRDS("/projectnb/talbot-lab-data/zrwerbin/temporal_forecast/data/clean/groupAbundances_EE509.rds")
# ```
# 
# Next, we subset to one particular group (Acidobacteria) and format the data for analysis. Microbial abundance (our response variable) is measured for a soil core, and there are a few soil cores that are replicates for a given plot. About 5-10 plots are in a site, and there are five sites across the country. The dataset therefore has 1095 soil cores, 67 plots, and 5 sites. 
# 
# ```{r}
rank.df <- d[[1]] # Subsetting bacterial phyla
rank.df$dates <- gsub("2016", "2015", rank.df$dates) # Replacing 2015 with 2016 to avoid a huge gap in dataset.
model.dat <- prepModelData(weather, plot.preds, rank.df, j=1) # Combine using custom function
dat <- model.dat[[1]]
y <- model.dat[[2]]
time.cov <- model.dat[[3]]
space.cov <- model.dat[[4]]
plot_site <- model.dat[[5]]
plot.truth <- model.dat[[6]]

# Create data object.
data <- list(y = as.matrix(y), 
             N.core = length(dat$y), 
             N.plot = length(unique(dat$plotID)),
             N.site = length(unique(dat$siteID)), 
             N.date = length(unique(dat$dateID)),
             plot_site = droplevels(as.factor(plot_site)),
             plotID = droplevels(as.factor(dat$plotID)),
             time.cov = time.cov,
             space.cov = space.cov
)
# ```
# 
# Let's take a look at the data we're using. We have temperature and precipitation data for each site and each month, and pH values for each plot. Covariates have been mean-centered. Y values range from 0 to 1 (closed interval).
# ```{r}
# temp.cov[,1:5]
# 
# precip.cov[,1:5]
# 
# head(pH.cov)
# 
# head(dat); dim(dat)
# ```
# 
# Now, let's look at and fit our model. The JAGS code has a data model at the core level, because each core is a replicate for one plot. This data is drawn from the beta distribution, with a logit link function to prevent any values outside of 0 or 1. The process model, with the environmental covariates, is at the plot level. We have random effects for each site, each plot, and each time point. 
# 
# ```{r}
model_string <- " model{

#### Core-level observations ####
for (t in 1:N.date){
  for (i in 1:N.core){
      y[i,t] ~ dbeta(shape1[plotID[i],t], shape2[plotID[i],t]) ## Data model: core observations drawn from alpha/beta
  }
}

#### Plot means - Process model ####
for (i in 1:N.plot){
  for (t in 2:N.date){ 
    logit(plot_mean[i,t]) <-  beta[1]*logit(plot_mean[i,t-1]) + 
                              beta[2]*time.cov[i,t,2] + beta[3]*time.cov[i,t,1] + 
                              inprod(beta[4:6], space.cov[i,1:3]) +
                              plot_effect[i] + time_effect[plot_site[i],t]

    # Convert plot mean into parameters for beta distribution
    shape1[i,t] <- plot_mean[i,t] * tau   
    shape2[i,t]  <- (1-plot_mean[i,t]) * tau 
  }
}

#### Priors ####

for (i in 1:N.site){
  site_effect[i] ~ dnorm(0,site_var)  # Prior on site random effects
  for (t in 1:N.date){
    time_effect[i,t] ~ dnorm(0, time_var) # Prior on time random effects
  }
}

for (i in 1:N.plot){
  plot_effect[i] ~ dnorm(site_effect[plot_site[i]], plot_var) # Prior on plot random effects
  plot_mean[i,1] ~ dbeta(1,3)             # Prior on plot means for first date 
  shape1[i,1] <- plot_mean[i,1] * tau      # alpha for first date
  shape2[i,1]  <- (1-plot_mean[i,1]) * tau  # beta for first date
}

# Coefficient priors
for(i in 1:6){
    beta[i] ~ dnorm(0,0.0001)
  }

# Variance priors
tau ~ dgamma(1,.1) 
plot_var ~ dgamma(1,.1) 
site_var ~ dgamma(1,.1) 
time_var ~ dgamma(1,.1) 
}"

monitor <- c("beta","tau","site_var","time_var",
             "plot_var","plot_mean","site_effect","plot_effect","time_effect")

pmod <- run.jags(model_string,
                 data = data,
                 adapt = 200,
                 burnin = 2000,
                 sample = 2000,
                 n.chains = 5,
                 thin = 3,
                 method = "parallel",
                 jags = "/share/pkg.7/jags/4.3.0/install/bin/jags",
                 monitor = monitor)

# # Pull out plot values
plot_mean <- summary(pmod, vars="plot_mean")
plot_out <- data.frame(plot_int_mean = plot_mean[,4],
                       plot_int_lo95 = plot_mean[,1],
                       plot_int_hi95 = plot_mean[,3])
plot_out$truth <- plot.truth$plot_mean
plot_out$plotID <- plot.truth$plotID
plot_out$dateCol <- as.Date(paste0(as.character(plot.truth$dateID), '01'), format='%Y%m%d')
plot_out$siteID <- plot.truth$siteID
plot_out$psrf <- plot_mean[,11]
plot_out$SSeff <- plot_mean[,9]

```

Let's view our model fit for a single plot:
```{r}
  mfit <- pmod$mcmc[[1]]
  # Create confidence interval for the calibration period.
  plotpreds <- mfit[,grep(paste0("plot_mean[1,"), colnames(mfit),fixed=TRUE)]
  plot.cal.ci <- apply(plotpreds,2,quantile,c(0.025,0.5,0.975))
  # Pull out predictive variance and convert to standard deviation
  tau <- summary(pmod, vars="tau")[4]
  # Create predictive interval
  plot.cal <- sapply(plot.cal.ci[2,], function (x) rbeta(500, mean(tau) * x, mean(tau) * (1 - x)))
  plot.cal.pi <- apply(plot.cal,2,quantile,c(0.025,0.5,0.975))
  # Create and view plot!
  plot(1:25,1:25,type='n', ylim=c(0,1), ylab="Relative Abundance", xlab = "Time")
  ecoforecastR::ciEnvelope(1:25,plot.cal.pi[1,],plot.cal.pi[3,],col=col.alpha("lightGreen",0.6))
  ecoforecastR::ciEnvelope(1:25,plot.cal.ci[1,],plot.cal.ci[3,],col=col.alpha("lightBlue",0.8))
  lines(1:25,plot.cal.ci[2,],col="blue")
  obs <- plot_out[grep(paste0("plot_mean[1,"), rownames(plot_out),fixed=T),]$truth
  points(obs)
```
